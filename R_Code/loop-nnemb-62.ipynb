{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T07:53:49.871756Z",
     "iopub.status.busy": "2023-04-18T07:53:49.869306Z",
     "iopub.status.idle": "2023-04-18T07:53:51.408055Z"
    }
   },
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(plyr)\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T07:53:52.766267Z",
     "iopub.status.busy": "2023-04-18T07:53:52.737513Z",
     "iopub.status.idle": "2023-04-18T07:53:52.792619Z"
    }
   },
   "outputs": [],
   "source": [
    "fonction_clean_data_1 <- function(dat) {\n",
    "  dat$VehGas <- factor(dat$VehGas)     \n",
    "  dat$n <- 1                            \n",
    "  dat$ClaimNb <- pmin(dat$ClaimNb, 4)   \n",
    "  dat$Exposure <- pmin(dat$Exposure, 1) \n",
    "  return(dat)\n",
    "}\n",
    "\n",
    "Poisson.Deviance <- function(pred, obs){200*(sum(pred)-sum(obs)+sum(log((obs/pred)^(obs))))/length(pred)}\n",
    "\n",
    "#########  feature pre-processing for GLM\n",
    "fonction_clean_data_2 <- function(dat2) {\n",
    "  dat2$AreaGLM <- as.integer(dat2$Area)\n",
    "  dat2$VehPowerGLM <- as.factor(pmin(dat2$VehPower,9))\n",
    "  VehAgeGLM <- cbind(c(0:110), c(1, rep(2,10), rep(3,100)))\n",
    "  dat2$VehAgeGLM <- as.factor(VehAgeGLM[dat2$VehAge+1,2])\n",
    "  dat2[,\"VehAgeGLM\"] <-relevel(dat2[,\"VehAgeGLM\"], ref=\"2\")\n",
    "  DrivAgeGLM <- cbind(c(18:100), c(rep(1,21-18), rep(2,26-21), rep(3,31-26), rep(4,41-31), rep(5,51-41), rep(6,71-51), rep(7,101-71)))\n",
    "  dat2$DrivAgeGLM <- as.factor(DrivAgeGLM[dat2$DrivAge-17,2])\n",
    "  dat2[,\"DrivAgeGLM\"] <-relevel(dat2[,\"DrivAgeGLM\"], ref=\"5\")\n",
    "  dat2$BonusMalusGLM <- as.integer(pmin(dat2$BonusMalus, 150))\n",
    "  dat2$DensityGLM <- as.numeric(log(dat2$Density))\n",
    "  dat2[,\"Region\"] <-relevel(dat2[,\"Region\"], ref=\"R24\")\n",
    "  dat2$AreaRT <- as.integer(dat2$Area)\n",
    "  dat2$VehGasRT <- as.integer(dat2$VehGas)\n",
    "  return(dat2)\n",
    "}\n",
    "\n",
    "# min-max-scaler:\n",
    "PreProcess.Continuous <- function(var1, dat2){\n",
    "  names(dat2)[names(dat2) == var1]  <- \"V1\"\n",
    "  dat2$X <- as.numeric(dat2$V1)\n",
    "  dat2$X <- 2*(dat2$X-min(dat2$X))/(max(dat2$X)-min(dat2$X))-1\n",
    "  names(dat2)[names(dat2) == \"V1\"]  <- var1\n",
    "  names(dat2)[names(dat2) == \"X\"]  <- paste(var1,\"X\", sep=\"\")\n",
    "  dat2\n",
    "}\n",
    "\n",
    "# pre-procecessing function:\n",
    "Features.PreProcess <- function(dat2){\n",
    "  dat2 <- PreProcess.Continuous(\"Area\", dat2)   \n",
    "  dat2 <- PreProcess.Continuous(\"VehPower\", dat2)   \n",
    "  dat2$VehAge <- pmin(dat2$VehAge,20)\n",
    "  dat2 <- PreProcess.Continuous(\"VehAge\", dat2)   \n",
    "  dat2$DrivAge <- pmin(dat2$DrivAge,90)\n",
    "  dat2 <- PreProcess.Continuous(\"DrivAge\", dat2)   \n",
    "  dat2$BonusMalus <- pmin(dat2$BonusMalus,150)\n",
    "  dat2 <- PreProcess.Continuous(\"BonusMalus\", dat2)   \n",
    "  dat2$VehBrandX <- as.integer(dat2$VehBrand)-1\n",
    "  dat2$VehGasX <- as.integer(dat2$VehGas)-1.5\n",
    "  dat2$Density <- round(log(dat2$Density),2)\n",
    "  dat2 <- PreProcess.Continuous(\"Density\", dat2)   \n",
    "  dat2$RegionX <- as.integer(dat2$Region)-1  # char R11,,R94 to number 0,,21\n",
    "  print(dat2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'81', '37', '71', '28', '70', '54', '59', '17', '79', \n",
    "            '30', '10', '97', '45', '39', '30', '91', '87', '56', '50', \n",
    "            '98', '44', '78', '23', '50', '16', '61', '7', '28', '89'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-18T07:55:09.204148Z",
     "iopub.status.busy": "2023-04-18T07:55:09.202441Z",
     "iopub.status.idle": "2023-04-18T08:49:31.041397Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_frame = data.frame(deviance_train = c(1), \n",
    "                        deviance_test = c(1), \n",
    "                        diff_train = c(1),\n",
    "                        diff_test = c(1),\n",
    "                        model = c(1))\n",
    "#,'81', '37', '71', '28'\n",
    "for (p in c('62', '81', '37', '71', '28', '70', '54', '59', '17', '79')) {\n",
    "  print(p)\n",
    "  str1 = '../input/cvalidation/data_learn_'\n",
    "  str2 = p\n",
    "  str3 = '.csv'\n",
    "  \n",
    "  result_learn = paste(str1,str2,str3,sep=\"\")\n",
    "  \n",
    "  learn <- read.csv(result_learn, header=TRUE, stringsAsFactors = TRUE)\n",
    "  \n",
    "  str1_t = '../input/cvalidation1/data_test_'\n",
    "  str2_t = p\n",
    "  str3_t = '.csv'\n",
    "  \n",
    "  result_test = paste(str1_t,str2_t,str3_t,sep=\"\")\n",
    "  \n",
    "  test <- read.csv(result_test, header=TRUE, stringsAsFactors = TRUE)\n",
    "  \n",
    "    \n",
    "  new <- rbind(learn, test)\n",
    "    \n",
    "  ## set the seed to make your partition reproducible\n",
    "  set.seed(62)\n",
    "  train_ind <- sample(seq_len(nrow(new)), size = floor(0.90 * nrow(new)))\n",
    "    \n",
    "  train <- new[train_ind, ]\n",
    "  test <- new[-train_ind, ]\n",
    "    \n",
    "  set.seed(62)\n",
    "  leanr_ind <- sample(seq_len(nrow(train)), size = floor(0.90 * nrow(train)))\n",
    "    \n",
    "  learn <- new[leanr_ind, ]\n",
    "  valid <- new[-leanr_ind, ]\n",
    "  \n",
    "learn <- fonction_clean_data_2(learn)\n",
    "test <- fonction_clean_data_2(test)\n",
    "\n",
    "learn <- Features.PreProcess(learn[,c(\"ClaimNb\", \"Exposure\", \"Area\",\"VehPower\",\"VehAge\",\"DrivAge\",\"BonusMalus\",\"VehBrand\",\"VehGas\",\"Density\", \"Region\")])  # keep original variables and fitGLM2 (CANN)\n",
    "test <- Features.PreProcess(test[,c(\"ClaimNb\", \"Exposure\", \"Area\",\"VehPower\",\"VehAge\",\"DrivAge\",\"BonusMalus\",\"VehBrand\",\"VehGas\",\"Density\", \"Region\")])\n",
    "  \n",
    "q0 <- length(c(\"AreaX\", \"VehPowerX\", \"VehAgeX\", \"DrivAgeX\", \"BonusMalusX\", \"VehGasX\", \"DensityX\"))\n",
    "    \n",
    "# learning data\n",
    "Xlearn <- as.matrix(learn[, c(\"AreaX\", \"VehPowerX\", \"VehAgeX\", \"DrivAgeX\", \"BonusMalusX\", \"VehGasX\", \"DensityX\")])  # design matrix learning sample\n",
    "Brlearn <- as.matrix(learn$VehBrandX)\n",
    "Relearn <- as.matrix(learn$RegionX)\n",
    "Ylearn <- as.matrix(learn$ClaimNb)\n",
    "    \n",
    "# testing data\n",
    "Xtest <- as.matrix(test[, c(\"AreaX\", \"VehPowerX\", \"VehAgeX\", \"DrivAgeX\", \"BonusMalusX\", \"VehGasX\", \"DensityX\")])    # design matrix test sample\n",
    "Brtest <- as.matrix(test$VehBrandX)\n",
    "Retest <- as.matrix(test$RegionX)\n",
    "Ytest <- as.matrix(test$ClaimNb)\n",
    "# choosing the right volumes for EmbNN and CANN\n",
    "Vlearn <- as.matrix(log(learn$Exposure))\n",
    "Vtest <- as.matrix(log(test$Exposure))\n",
    "\n",
    "(lambda.hom <- sum(learn$ClaimNb)/sum(learn$Exposure))\n",
    "    \n",
    "# hyperparameters of the neural network architecture (as specified in \"01 CANN approach.r\") \n",
    "q1 <- 20 # Number of neuron in hidden layer 1\n",
    "q2 <- 15\n",
    "q3 <- 10\n",
    "d <- 2   # dimensions embedding layers for categorical features\n",
    "(BrLabel <- length(unique(learn$VehBrandX))) \n",
    "(ReLabel <- length(unique(learn$RegionX)))   \n",
    "\n",
    "# define the network architecture\n",
    "Design   <- layer_input(shape = c(q0),  dtype = 'float32', name = 'Design')\n",
    "VehBrand <- layer_input(shape = c(1),   dtype = 'int32', name = 'VehBrand')\n",
    "Region   <- layer_input(shape = c(1),   dtype = 'int32', name = 'Region')\n",
    "LogVol   <- layer_input(shape = c(1),   dtype = 'float32', name = 'LogVol')\n",
    "\n",
    "BrandEmb = VehBrand %>% \n",
    "  layer_embedding(input_dim = BrLabel, output_dim = d, input_length = 1, name = 'BrandEmb') %>%\n",
    "  layer_flatten(name='Brand_flat')\n",
    "\n",
    "RegionEmb = Region %>% \n",
    "  layer_embedding(input_dim = ReLabel, output_dim = d, input_length = 1, name = 'RegionEmb') %>%\n",
    "  layer_flatten(name='Region_flat')\n",
    "\n",
    "Network = list(Design, BrandEmb, RegionEmb) %>% layer_concatenate(name='concate') %>% \n",
    "  layer_dense(units=q1, activation='tanh', name='hidden1') %>%\n",
    "  layer_dense(units=q2, activation='tanh', name='hidden2') %>%\n",
    "  layer_dense(units=q3, activation='tanh', name='hidden3') %>%\n",
    "  layer_dense(units=1, activation='linear', name='Network', \n",
    "              weights=list(array(0, dim=c(q3,1)), array(log(lambda.hom), dim=c(1))))\n",
    "\n",
    "Response = list(Network, LogVol) %>% layer_add(name='Add') %>% \n",
    "  layer_dense(units=1, activation=k_exp, name = 'Response', trainable=FALSE,\n",
    "              weights=list(array(1, dim=c(1,1)), array(0, dim=c(1))))\n",
    "\n",
    "model <- keras_model(inputs = c(Design, VehBrand, Region, LogVol), outputs = c(Response))\n",
    "model %>% compile(optimizer = optimizer_nadam(), loss = 'poisson')\n",
    "\n",
    "#summary(model)\n",
    "    \n",
    "set.seed(42)\n",
    "fit <- model %>% fit(list(Xlearn, Brlearn, Relearn, Vlearn), Ylearn, epochs=450, \n",
    "                       batch_size=10000, verbose=1, validation_split=0)    \n",
    "    \n",
    "# calculating the predictions\n",
    "learn$fitNNemb <- as.vector(model %>% predict(list(Xlearn, Brlearn, Relearn, Vlearn)))\n",
    "test$fitNNemb <- as.vector(model %>% predict(list(Xtest, Brtest, Retest, Vtest))) \n",
    "    \n",
    "# defining new row data frame\n",
    "new_row =  c(Poisson.Deviance(learn$fitNNemb, learn$ClaimNb),\n",
    "               Poisson.Deviance(test$fitNNemb, test$ClaimNb),\n",
    "               ((sum(learn$fitNNemb) - sum(learn$ClaimNb))/sum(learn$ClaimNb))*100, \n",
    "               ((sum(test$fitNNemb) - sum(test$ClaimNb))/sum(test$ClaimNb))*100, \n",
    "               'NNemb')\n",
    "  \n",
    "  data_frame <- rbind(data_frame, new_row)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T08:49:31.045158Z",
     "iopub.status.busy": "2023-04-18T08:49:31.043863Z",
     "iopub.status.idle": "2023-04-18T08:49:31.080977Z"
    }
   },
   "outputs": [],
   "source": [
    "data_frame = data_frame[-1,]\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T08:49:31.084886Z",
     "iopub.status.busy": "2023-04-18T08:49:31.083517Z",
     "iopub.status.idle": "2023-04-18T08:49:31.102618Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data_frame$deviance_test)\n",
    "print(data_frame$deviance_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
