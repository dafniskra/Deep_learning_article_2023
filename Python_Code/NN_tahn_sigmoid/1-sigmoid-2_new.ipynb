{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T15:04:29.693601Z",
     "iopub.status.busy": "2022-04-27T15:04:29.693321Z",
     "iopub.status.idle": "2022-04-27T15:04:29.700761Z",
     "shell.execute_reply": "2022-04-27T15:04:29.700069Z",
     "shell.execute_reply.started": "2022-04-27T15:04:29.693573Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, add, BatchNormalization, concatenate, Embedding, Flatten \n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.initializers import RandomNormal, Ones\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from numpy import array\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function PD: Calculate Poisson Deviance\n",
    "def PD_function(pred, obs):\n",
    "    PD = 200*( sum(pred) - sum(obs) + sum( np.log( (obs/pred)**(obs) ) ) )\n",
    "    return PD/len(pred)\n",
    "    \n",
    "# evaluate a single mlp model\n",
    "def evaluate_model(trainX, trainy, train_expo, trainbrand, trainregion,\n",
    "                   activ_fonction_0, activ_fonction_1, activ_fonction_2,\n",
    "                   nb_neurones_0, nb_neurones_1, nb_neurones_2, \n",
    "                   drop_out_1, drop_out_2\n",
    "                  ):\n",
    "    \n",
    "    first_input = Input(shape=(7))\n",
    "    \n",
    "    brand_input = Input(shape=(1))\n",
    "    region_input = Input(shape=(1))    \n",
    "    \n",
    "    \n",
    "    Embedding_brand = Flatten()(Embedding(input_dim = 11, output_dim = 2)(brand_input))\n",
    "    Embedding_region = Flatten()(Embedding(input_dim = 22, output_dim = 2)(region_input))\n",
    "    \n",
    "    \n",
    "    merge_one = tf.keras.layers.Concatenate()([Embedding_brand, Embedding_region, first_input])\n",
    "    \n",
    "    first_dense_1 = Dense(nb_neurones_1)(merge_one)\n",
    "    act_dense_1 = Activation(activ_fonction_1)(first_dense_1)\n",
    "    \n",
    "    first_dense_2 = Dense(nb_neurones_2)(act_dense_1)\n",
    "    act_dense_2 = Activation(activ_fonction_2)(first_dense_2)\n",
    "\n",
    "    first_dense_3 = Dense(1, bias_initializer=tf.keras.initializers.Constant(value=-2.29881790925729), \n",
    "                          kernel_initializer=tf.keras.initializers.Zeros())(act_dense_2)\n",
    "    act_dense_3 = Activation('linear')(first_dense_3)\n",
    "\n",
    "    second_input = Input(shape=(1, ))\n",
    "\n",
    "    second_dense_1 = Dense(1, \n",
    "                           bias_initializer=tf.keras.initializers.Constant(value=0), \n",
    "                           kernel_initializer=tf.keras.initializers.Ones(), \n",
    "                           trainable=False)(add([act_dense_3, second_input])) \n",
    "    final_output = Activation('exponential')(second_dense_1) \n",
    "\n",
    "    model_ = Model(inputs=[first_input, second_input, brand_input, region_input], outputs=final_output)\n",
    "\n",
    "    model_.compile(optimizer=Nadam(), loss='poisson')\n",
    "    \n",
    "    model_.fit([trainX, train_expo, trainbrand, trainregion], trainy, epochs=450, verbose=0,\n",
    "                   batch_size=10000\n",
    "                  )\n",
    "\n",
    "    return model_, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T15:04:29.740438Z",
     "iopub.status.busy": "2022-04-27T15:04:29.740093Z",
     "iopub.status.idle": "2022-04-27T15:04:29.769486Z",
     "shell.execute_reply": "2022-04-27T15:04:29.768627Z",
     "shell.execute_reply.started": "2022-04-27T15:04:29.740409Z"
    }
   },
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, X_test, expo_test, brand_test, region_test):\n",
    "    \n",
    "    # make predictions\n",
    "    yhats = [model.predict([X_test, expo_test, brand_test, region_test]) for model in members]\n",
    "    yhats = array(yhats)\n",
    "    \n",
    "    result = np.mean(yhats, axis=0).flatten() \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members_bis(members, testX, testexpo, testbrand, testregion):\n",
    "    \n",
    "    # select a subset of members\n",
    "    subset = members[:len(members)]\n",
    "    \n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(subset, testX, testexpo, testbrand, testregion)\n",
    "    \n",
    "    # calculate accuracy \n",
    "    return yhat\n",
    "\n",
    "\n",
    "def Ensemble_fit(Xtrain_, ytrain_, expotrain_, brandtrain_, regiontrain_,\n",
    "                 samples=30, rate_OOB=0.2, type_ = \"Bagging\", ver_freq_train=True):\n",
    "    \n",
    "    n_splits = samples\n",
    "    scores_, members_ = list(), list()\n",
    "   \n",
    "    activ_fonction_0, activ_fonction_1, activ_fonction_2 = random.sample([\"sigmoid\"], 1), random.sample([\"sigmoid\"], 1), random.sample([\"sigmoid\"], 1)\n",
    "    nb_neurones_0, nb_neurones_1, nb_neurones_2 = random.sample([20], 1), random.sample([15], 1), random.sample([10], 1)\n",
    "    drop_out_1, drop_out_2 = random.sample([0.02, 0.04, 0.06, 0.08], 1), random.sample([0.02, 0.04, 0.06, 0.08], 1)\n",
    "        \n",
    "        # evaluate model\n",
    "    model, test_acc = evaluate_model(Xtrain_, ytrain_, expotrain_, brandtrain_, regiontrain_, \n",
    "                                     activ_fonction_0[0], activ_fonction_1[0], activ_fonction_2[0], \n",
    "                                     nb_neurones_0[0], nb_neurones_1[0], nb_neurones_2[0], \n",
    "                                     drop_out_1[0], drop_out_2[0])\n",
    "        \n",
    "    print('> OOB > %.3f' % test_acc)\n",
    "    scores_.append(test_acc)\n",
    "    members_.append(model)   \n",
    "    \n",
    "    return members_, scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", 81, 37 ,71, 28, 70, 54, 59, 17, 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T15:06:46.480807Z",
     "iopub.status.busy": "2022-04-27T15:06:46.480518Z",
     "iopub.status.idle": "2022-04-27T15:40:03.181128Z",
     "shell.execute_reply": "2022-04-27T15:40:03.179715Z",
     "shell.execute_reply.started": "2022-04-27T15:06:46.480777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "> OOB > 0.000\n",
      "2119/2119 [==============================] - 5s 2ms/step\n",
      "17162/17162 [==============================] - 38s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRASNIQ\\AppData\\Local\\Temp\\ipykernel_22096\\540695334.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_poisson = df_poisson.append(cnt, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "> OOB > 0.000\n",
      "2119/2119 [==============================] - 5s 2ms/step\n",
      "17162/17162 [==============================] - 39s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRASNIQ\\AppData\\Local\\Temp\\ipykernel_22096\\540695334.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_poisson = df_poisson.append(cnt, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "> OOB > 0.000\n",
      "2119/2119 [==============================] - 3s 2ms/step\n",
      "17162/17162 [==============================] - 17s 990us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRASNIQ\\AppData\\Local\\Temp\\ipykernel_22096\\540695334.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_poisson = df_poisson.append(cnt, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "> OOB > 0.000\n",
      "2119/2119 [==============================] - 2s 794us/step\n",
      "17162/17162 [==============================] - 13s 775us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRASNIQ\\AppData\\Local\\Temp\\ipykernel_22096\\540695334.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_poisson = df_poisson.append(cnt, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "> OOB > 0.000\n",
      "2119/2119 [==============================] - 2s 938us/step\n",
      "17162/17162 [==============================] - 15s 848us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRASNIQ\\AppData\\Local\\Temp\\ipykernel_22096\\540695334.py:91: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_poisson = df_poisson.append(cnt, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_poisson = pd.DataFrame()\n",
    "\n",
    "table_name = [\"deviance_train\", \"deviance_test\", \"diff_train\", \"diff_test\"]\n",
    "\n",
    "for p in [62, 54, 42, 88, 29]:\n",
    "    \n",
    "    print(p)\n",
    "    \n",
    "    data_learn = pd.read_csv(r'C:\\Users\\KRASNIQ\\Documents\\These_1.1\\data\\data_learn_'+str(62)+'.csv')\n",
    "    data_test = pd.read_csv(r'C:\\Users\\KRASNIQ\\Documents\\These_1.1\\data\\data_test_'+str(62)+'.csv')\n",
    "    \n",
    "    nex_data = pd.concat([data_learn, data_test])\n",
    "    \n",
    "    data_learn_, data_test_ = train_test_split(nex_data, stratify=nex_data['ClaimNb'], test_size=0.1, random_state=p)\n",
    "    \n",
    "    data_learn_['Exposure'] = data_learn_['Exposure'].clip(upper=1)\n",
    "    data_test_['Exposure'] = data_test_['Exposure'].clip(upper=1)\n",
    "    \n",
    "    data_learn_['Area'] = data_learn_['Area'].map({\"A\": 1, \"B\": 2,\"C\": 3,\"D\": 4,\"E\": 5,\"F\": 6,})\n",
    "    data_test_['Area'] = data_test_['Area'].map({\"A\": 1, \"B\": 2,\"C\": 3,\"D\": 4,\"E\": 5,\"F\": 6,})\n",
    "    \n",
    "    data_learn_ = data_learn_.drop([\"Area_class_1\",\"Area_class_2\",\"Area_class_3\",\"Area_class_4\",'ClaimAmount', 'DrivAge', 'BonusMalus',\n",
    "                                    \"VehBrand_class_1\", \"VehBrand_class_2\", \"VehBrand_class_3\",\n",
    "                                    'Density',\"Region_class_1\", \"Region_class_2\", \"Region_class_3\", \"Region_class_4\" , \n",
    "                                    'VehAge', 'VehGas', \"VehGas_class_2\"], axis=1)\n",
    "\n",
    "    data_test_ = data_test_.drop([\"Area_class_1\",\"Area_class_2\",\"Area_class_3\",\"Area_class_4\",'ClaimAmount', 'DrivAge', 'BonusMalus',\n",
    "                                  \"VehBrand_class_1\", \"VehBrand_class_2\", \"VehBrand_class_3\",\n",
    "                                  'Density',\"Region_class_1\", \"Region_class_2\", \"Region_class_3\", \"Region_class_4\" , \n",
    "                                  'VehAge', 'VehGas', \"VehGas_class_2\"], axis=1)\n",
    "    \n",
    "    # train test split \n",
    "    X_train__, X_valid__ = train_test_split(data_learn_, stratify=data_learn_['ClaimNb'], test_size=0.1, random_state=p)\n",
    "    \n",
    "    \n",
    "    #################### label encoding\n",
    "    \n",
    "    le_region = preprocessing.LabelEncoder()\n",
    "    le_region.fit(X_train__['Region'])\n",
    "\n",
    "    le_brand = preprocessing.LabelEncoder()\n",
    "    le_brand.fit(X_train__['VehBrand'])\n",
    "    \n",
    "    y_train = np.array(X_train__.filter(['ClaimNb']))\n",
    "    log_exp_train= np.array(np.log(X_train__.filter(['Exposure'])))\n",
    "    region_train = np.array(le_region.transform(X_train__['Region']))\n",
    "    brand_train = np.array(le_brand.transform(X_train__['VehBrand']))\n",
    "    x_train = X_train__.drop(columns=['ClaimNb', 'Exposure', 'VehBrand', 'Region'])\n",
    "\n",
    "    y_valid = np.array(X_valid__.filter(['ClaimNb']))\n",
    "    log_exp_valid= np.array(np.log(X_valid__.filter(['Exposure'])))\n",
    "    region_valid = np.array(le_region.transform(X_valid__['Region']))\n",
    "    brand_valid = np.array(le_brand.transform(X_valid__['VehBrand']))\n",
    "    x_valid = X_valid__.drop(columns=['ClaimNb', 'Exposure', 'VehBrand', 'Region'])\n",
    "    \n",
    "    #valid\n",
    "    y_test = np.array(data_test_.filter(['ClaimNb']))\n",
    "    log_exp_test = np.array(np.log(data_test_.filter(['Exposure'])))\n",
    "    region_test = np.array(le_region.transform(data_test_['Region']))\n",
    "    brand_test = np.array(le_brand.transform(data_test_['VehBrand']))\n",
    "    x_test = data_test_.drop(columns=['ClaimNb', 'Exposure', 'VehBrand', 'Region'])\n",
    "    \n",
    "    #feature eng\n",
    "    cs = MinMaxScaler()\n",
    "    X_train = np.array(2*((x_train - x_train.min())/(x_train.max()-x_train.min())) - 1)\n",
    "    X_valid = np.array(2*((x_valid - x_train.min())/(x_train.max()-x_train.min())) - 1)\n",
    "    X_test = np.array(2*((x_test - x_train.min())/(x_train.max()-x_train.min())) - 1)\n",
    "    \n",
    "    \n",
    "    members, scores = Ensemble_fit(X_train, y_train, log_exp_train, brand_train, region_train,\n",
    "                                   samples=1, rate_OOB=0, type_ = \"Bagging\",\n",
    "                                   ver_freq_train=False)\n",
    "\n",
    "    \n",
    "    predictions_test = evaluate_n_members_bis(members, X_test, log_exp_test, brand_test, region_test)\n",
    "    predictions_train = evaluate_n_members_bis(members, X_train, log_exp_train, brand_train, region_train)\n",
    "\n",
    "    #deviance\n",
    "    table_modal= [np.round(PD_function(predictions_train, y_train.flatten()),6),\n",
    "                  np.round(PD_function(predictions_test, y_test.flatten()),6),\n",
    "                  (sum(predictions_train) - sum(y_train.flatten()))/sum(y_train.flatten())*100,\n",
    "                  (sum(predictions_test) -sum(y_test.flatten()))/sum(y_test.flatten())*100]\n",
    "    \n",
    "    table_name = [\"deviance_train\", \"deviance_test\", \"diff_train\", \"diff_test\"]\n",
    "\n",
    "    cnt = dict()\n",
    "    k=0\n",
    "    for word in table_name:\n",
    "        cnt[word] = table_modal[k]\n",
    "        k = k+1\n",
    "    df_poisson = df_poisson.append(cnt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-27T15:40:03.182302Z",
     "iopub.status.idle": "2022-04-27T15:40:03.182774Z",
     "shell.execute_reply": "2022-04-27T15:40:03.182562Z",
     "shell.execute_reply.started": "2022-04-27T15:40:03.182534Z"
    }
   },
   "outputs": [],
   "source": [
    "df_poisson['model']=[\"cv-bagging-1\"]*len(df_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-27T15:05:28.797735Z",
     "iopub.status.idle": "2022-04-27T15:05:28.798055Z",
     "shell.execute_reply": "2022-04-27T15:05:28.797915Z",
     "shell.execute_reply.started": "2022-04-27T15:05:28.797878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviance_train</th>\n",
       "      <th>deviance_test</th>\n",
       "      <th>diff_train</th>\n",
       "      <th>diff_test</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.396713</td>\n",
       "      <td>31.563784</td>\n",
       "      <td>0.800923</td>\n",
       "      <td>0.800429</td>\n",
       "      <td>cv-bagging-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.423008</td>\n",
       "      <td>31.143009</td>\n",
       "      <td>-1.015073</td>\n",
       "      <td>-0.738126</td>\n",
       "      <td>cv-bagging-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.307834</td>\n",
       "      <td>31.114458</td>\n",
       "      <td>4.511021</td>\n",
       "      <td>4.467360</td>\n",
       "      <td>cv-bagging-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.409858</td>\n",
       "      <td>31.495955</td>\n",
       "      <td>1.572798</td>\n",
       "      <td>1.778204</td>\n",
       "      <td>cv-bagging-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.195336</td>\n",
       "      <td>31.466368</td>\n",
       "      <td>-2.313896</td>\n",
       "      <td>-2.206065</td>\n",
       "      <td>cv-bagging-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deviance_train  deviance_test  diff_train  diff_test         model\n",
       "0       31.396713      31.563784    0.800923   0.800429  cv-bagging-1\n",
       "1       31.423008      31.143009   -1.015073  -0.738126  cv-bagging-1\n",
       "2       31.307834      31.114458    4.511021   4.467360  cv-bagging-1\n",
       "3       31.409858      31.495955    1.572798   1.778204  cv-bagging-1\n",
       "4       31.195336      31.466368   -2.313896  -2.206065  cv-bagging-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-27T15:05:28.799311Z",
     "iopub.status.idle": "2022-04-27T15:05:28.799679Z",
     "shell.execute_reply": "2022-04-27T15:05:28.799533Z",
     "shell.execute_reply.started": "2022-04-27T15:05:28.799515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.346549800000002, 31.3567148, 0.711154445961772, 0.8203602422698459)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poisson[\"deviance_train\"].mean(), df_poisson[\"deviance_test\"].mean(), df_poisson[\"diff_train\"].mean(), df_poisson[\"diff_test\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0958314374941744,\n",
       " 0.21133376283428984,\n",
       " 2.6134395818940725,\n",
       " 2.5400097505961656)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poisson[\"deviance_train\"].std(), df_poisson[\"deviance_test\"].std(), df_poisson[\"diff_train\"].std(), df_poisson[\"diff_test\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
